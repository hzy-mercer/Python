{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d973eb-0bee-4ac3-adb8-b0d352a985cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ce8be-00b2-4cde-87c1-40b51076741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the module 'sys' allows istalling module from inside Jupyter\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "!{sys.executable} -m pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Natrual Language ToolKit (NLTK)\n",
    "!{sys.executable} -m pip install nltk\n",
    "import nltk\n",
    "\n",
    "!{sys.executable} -m pip install sklearn\n",
    "from sklearn import metrics\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import  CountVectorizer #bag-of-words vectorizer \n",
    "from sklearn.decomposition import LatentDirichletAllocation #package for LDA\n",
    "\n",
    "# Plotting tools\n",
    "\n",
    "from pprint import pprint\n",
    "!{sys.executable} -m pip install pyLDAvis #visualizing LDA\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#define text normalization function\n",
    "%run ./Text_Normalization_Function.ipynb #defining text normalization function\n",
    "\n",
    "#ignore warnings about future changes in functions as they take too much space\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec949c6-96c6-4ec6-9ec5-911b43ec1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "data = pd.read_csv('/Users/Mercer/Desktop/origin_data.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3243-59f5-439c-85c7-fc9f5d656a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataslice = data[[\"asin\",\"reviewText\",\"overall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8437e576-c781-41ee-8940-2d5802655a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tem = range(len(dataslice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d78ee4-67df-429b-ab3f-677c9e04277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_overall_1_tem = []\n",
    "for i in index_tem:\n",
    "    if dataslice.loc[i,\"overall\"] == 1: # rating\n",
    "        tem = dataslice.loc[i,\"reviewText\"]\n",
    "        corpus_overall_1_tem.append(tem)\n",
    "\n",
    "index = range(len(corpus_overall_1_tem))\n",
    "corpus_overall_1 = []\n",
    "for ii in index:\n",
    "    if type(corpus_overall_1_tem[ii]) == str:\n",
    "        corpus_overall_1.append(corpus_overall_1_tem[ii])\n",
    "len(corpus_overall_1)\n",
    "\n",
    "\n",
    "#End of dataset preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76073d9d-0499-4443-9423-d29edf3d97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "def get_topic_words(vectorizer, lda_model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_words = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_word_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_words.append(keywords.take(top_word_locs).tolist())\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d9315-8ecc-41bf-a9d5-439ab5eefba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_corpus_overall_1 = normalize_corpus(corpus_overall_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6517b-57d8-4627-8660-7897f1ee3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the bag-of-words vectorizer:\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "#vectorize the normalized data:\n",
    "bow_corpus_overall_1 = bow_vectorizer.fit_transform(normalized_corpus_overall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3daa92-4b17-4ceb-b122-3837c06296dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = bow_corpus_overall_1.todense(), columns = bow_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499d18b-3f0b-4e48-ac10-5f084d6d2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_corpus_overall_1 = LatentDirichletAllocation(n_components=2, max_iter=500,\n",
    "                                           doc_topic_prior = 0.9,\n",
    "                                           topic_word_prior = 0.9).fit(bow_corpus_overall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8587b5-e3cf-446a-8980-94dc70306063",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_top_words = 50\n",
    "display_topics(lda_corpus_overall_1, bow_vectorizer.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4519f-9700-4f6f-ab9d-1fb5a1274d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = lda_corpus_overall_1.components_ / lda_corpus_overall_1.components_.sum(axis=1)[:, np.newaxis]\n",
    "pd.DataFrame(word_weights.T, index = bow_vectorizer.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04a2ec-85a0-4ed4-b482-e6a0dae40751",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = lda_corpus_overall_1.components_ / lda_corpus_overall_1.components_.sum(axis=1)[:, np.newaxis]\n",
    "word_weights_df = pd.DataFrame(word_weights.T, \n",
    "                               index = bow_vectorizer.get_feature_names(), \n",
    "                               columns = [\"Topic_\" + str(i) for i in range(2)])\n",
    "word_weights_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935f8e0-7c0b-4400-bd41-62544e19d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights_df.sort_values(by='Topic_0',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58e38b-3c1e-4889-9c53-5cadc4d24e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to display result in the Jupyter notebook\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
    "pyLDAvis.sklearn.prepare(lda_corpus_overall_1, bow_corpus_overall_1, bow_vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce31b7-d663-4fa0-9e64-cd1e35d3dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_corpus_overall_1_3_topics = LatentDirichletAllocation(n_components=3, max_iter=100,\n",
    "                                     doc_topic_prior = 0.25,\n",
    "                                     topic_word_prior = 0.25).fit(bow_corpus_overall_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438a781-8f2c-4649-9f1a-ea3e95c8d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to display result in the Jupyter notebook\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#run the visualization [mds is a function to use for visualizing the \"distance\" between topics]\n",
    "pyLDAvis.sklearn.prepare(lda_corpus_overall_1_3_topics, bow_corpus_overall_1, bow_vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a378704-1d65-45db-8a2b-c85b76ca0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_corpus_overall_1_topic_weights = lda_corpus_overall_1.transform(bow_corpus_overall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c51201-5b52-49b9-a304-710e573db54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of document \"names\" and topic \"names\" (\"names\" are just indecies)\n",
    "doc_names = [\"Doc_\" + str(i) for i in range(len(normalized_corpus_overall_1))]\n",
    "topic_names = [\"Topic_\" + str(i) for i in range(2)]\n",
    "\n",
    "#convert to dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_corpus_overall_1_topic_weights, 4), columns=topic_names, index=doc_names)\n",
    "df_document_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1723b8-15dd-4bc6-9a7d-b29891b7650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector of indecies for columns with the highest value by each row in df_document_topic\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "\n",
    "#add dominant_topic as a column to df_document_topic\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "df_document_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5606c-963e-4544-96bf-bcf612cc5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install gensim\n",
    "import gensim\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b027d09-7bcc-4dbd-adc3-62e8d51b2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the corpus\n",
    "corpus_overall_1_tokenized = [tokenize_text(normalized_corpus_overall_1[doc_id]) for doc_id in range(len(normalized_corpus_overall_1))]\n",
    "\n",
    "#Dictionary of the corpus:\n",
    "news_dictionary = Dictionary(corpus_overall_1_tokenized)\n",
    "\n",
    "#Bag-of-words representation for each document of the corpus:\n",
    "corpus_overall_1_bow = [news_dictionary.doc2bow(doc) for doc in corpus_overall_1_tokenized]\n",
    "\n",
    "#top 20 words for each topic (using the function defined in session prep)\n",
    "topic_topwords = get_topic_words(vectorizer = bow_vectorizer, lda_model = lda_corpus_overall_1, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc279a-25ee-45a6-ac1e-7f657f6fe57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(topics=topic_topwords, \n",
    "                    corpus = corpus_overall_1_bow , \n",
    "                    dictionary = news_dictionary, coherence='u_mass')\n",
    "print(\"Coherence score for the model: \", np.round(cm.get_coherence(), 4))  # get coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a8b16-f5f5-4476-9ba1-4d3e344c41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coherence score by topic (higher values are better): \", np.round(cm.get_coherence_per_topic(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03adfb-13b7-474b-a80d-592c90bb1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log-Likelihood (higher values are better): \", lda_corpus_overall_1.score(bow_corpus_overall_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033eb03-344b-4a1f-a5d2-5c8f55e760be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Perplexity (lower values are better): \", lda_corpus_overall_1.perplexity(bow_corpus_overall_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99b6dc-16e0-4fa8-977e-1e7dc2f7460c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc3355-3d89-4403-aff3-5ea0b42d9dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5553471-653e-4620-b637-eb27943ed2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
